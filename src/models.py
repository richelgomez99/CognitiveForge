"""
Data models for the CognitiveForge dialectical synthesis system.

This module defines Pydantic models for structured LLM outputs and the AgentState TypedDict
for LangGraph state management.
"""

from typing import List, Optional, Annotated
from typing_extensions import TypedDict
from pydantic import BaseModel, Field, field_validator
from langgraph.graph import add_messages


# =============================================================================
# Pydantic Models for Structured LLM Outputs
# =============================================================================

class Evidence(BaseModel):
    """
    Evidence supporting a claim in the dialectical process.
    
    Attributes:
        source_url: URL of the source document or research paper
        snippet: Relevant text snippet from the source
        relevance_score: Optional relevance score (0.0-1.0)
    """
    source_url: str = Field(description="URL of the source document")
    snippet: str = Field(description="Relevant text excerpt from source", min_length=10)
    relevance_score: Optional[float] = Field(default=None, description="Relevance score (0.0-1.0)", ge=0.0, le=1.0)
    
    @field_validator('source_url')
    @classmethod
    def validate_url(cls, v: str) -> str:
        """Ensure source_url is non-empty."""
        if not v or not v.strip():
            raise ValueError("source_url cannot be empty")
        return v.strip()


class Thesis(BaseModel):
    """
    Analyst's initial claim with supporting evidence.
    
    Attributes:
        claim: The main claim or hypothesis
        reasoning: Explanation of how evidence supports the claim
        evidence: List of Evidence objects (minimum 2 required)
    """
    claim: str = Field(description="Main claim or hypothesis", min_length=20)
    reasoning: str = Field(description="Explanation connecting evidence to claim", min_length=50)
    evidence: List[Evidence] = Field(description="Supporting evidence (min 2)", min_length=2)
    
    @field_validator('evidence')
    @classmethod
    def validate_evidence_count(cls, v: List[Evidence]) -> List[Evidence]:
        """Ensure at least 2 evidence items are provided."""
        if len(v) < 2:
            raise ValueError("Thesis must have at least 2 evidence items")
        return v


class Antithesis(BaseModel):
    """
    Skeptic's evaluation of the Thesis, identifying contradictions or weaknesses.
    
    Attributes:
        contradiction_found: Whether contradictions or weaknesses were identified
        counter_claim: Alternative interpretation or refutation (if contradiction found)
        conflicting_evidence: List of Evidence contradicting the Thesis
        critique: Detailed explanation of identified weaknesses
    """
    contradiction_found: bool = Field(description="Whether contradictions were identified")
    counter_claim: Optional[str] = Field(default=None, description="Alternative interpretation or refutation")
    conflicting_evidence: List[Evidence] = Field(default_factory=list, description="Evidence contradicting the Thesis")
    critique: str = Field(description="Detailed explanation of weaknesses or contradictions", min_length=30)
    
    @field_validator('counter_claim')
    @classmethod
    def validate_counter_claim(cls, v: Optional[str], info) -> Optional[str]:
        """Ensure counter_claim exists if contradiction_found is True."""
        if info.data.get('contradiction_found') and not v:
            raise ValueError("counter_claim is required when contradiction_found is True")
        return v


class Synthesis(BaseModel):
    """
    Synthesizer's novel insight integrating Thesis and Antithesis.
    
    Attributes:
        novel_insight: The synthesized novel insight or conclusion
        supporting_claims: List of claims from thesis/antithesis that support synthesis
        evidence_lineage: List of all unique source URLs (min 3)
        confidence_score: Confidence in the synthesis (0.0-1.0)
        novelty_score: Self-assessed novelty (0.0-1.0), evaluated by Synthesizer
        reasoning: Explanation of synthesis derivation
    """
    novel_insight: str = Field(description="Synthesized novel insight or conclusion", min_length=50)
    supporting_claims: List[str] = Field(description="Claims supporting the synthesis")
    evidence_lineage: List[str] = Field(description="All unique source URLs (min 3)", min_length=3)
    confidence_score: float = Field(description="Confidence in synthesis (0.0-1.0)", ge=0.0, le=1.0)
    novelty_score: float = Field(
        description="Self-assessed novelty (0.0-1.0) generated by Synthesizer in same LLM call; evaluates how novel the synthesis is compared to input thesis and antithesis",
        ge=0.0,
        le=1.0
    )
    reasoning: str = Field(description="Explanation of synthesis derivation", min_length=50)
    
    @field_validator('evidence_lineage')
    @classmethod
    def validate_evidence_lineage(cls, v: List[str]) -> List[str]:
        """Ensure at least 3 unique source URLs."""
        unique_urls = list(set(v))
        if len(unique_urls) < 3:
            raise ValueError("evidence_lineage must contain at least 3 unique source URLs")
        return unique_urls
    
    @field_validator('confidence_score', 'novelty_score')
    @classmethod
    def validate_scores(cls, v: float) -> float:
        """Ensure scores are within valid range."""
        if not 0.0 <= v <= 1.0:
            raise ValueError("Scores must be between 0.0 and 1.0")
        return v


# =============================================================================
# AgentState for LangGraph
# =============================================================================

class AgentState(TypedDict):
    """
    Central state for the dialectical synthesis LangGraph.
    
    This TypedDict is passed between all agent nodes and accumulates state
    throughout the graph execution.
    
    Attributes:
        messages: Accumulated messages using LangGraph's add_messages reducer
        original_query: The user's research query
        current_thesis: Latest Thesis from Analyst
        current_antithesis: Latest Antithesis from Skeptic
        final_synthesis: Final Synthesis from Synthesizer
        contradiction_report: Description of contradictions (from Skeptic)
        iteration_count: Number of iterations through the debate cycle
        procedural_memory: Procedural heuristics for agent learning (Tier 3)
    """
    messages: Annotated[list, add_messages]
    original_query: str
    current_thesis: Optional[Thesis]
    current_antithesis: Optional[Antithesis]
    final_synthesis: Optional[Synthesis]
    contradiction_report: str
    iteration_count: int
    procedural_memory: str  # For Tier 3 compatibility

